{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Dict, List, Tuple\n",
    "\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "\n",
    "from pysolotools.consumers import Solo\n",
    "from pysolotools.converters.solo2coco import SOLO2COCOConverter\n",
    "from pysolotools.core.models import KeypointAnnotationDefinition, RGBCameraCapture\n",
    "from pysolotools.core.models import BoundingBox2DLabel, BoundingBox2DAnnotation\n",
    "from pysolotools.core.models import BoundingBox3DLabel, BoundingBox3DAnnotation\n",
    "from pysolotools.core.models import Frame, Capture\n",
    "\n",
    "from scipy.spatial.transform import Rotation as R\n",
    "\n",
    "from torchvision.datasets import ImageFolder\n",
    "from torchvision.models import swin_v2_t, Swin_V2_T_Weights\n",
    "# from torch.utils.data import ConcatDataset, DataLoader\n",
    "\n",
    "import torch\n",
    "from torch import nn\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import utils\n",
    "# %matplotlib ipympl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_folder = 'D:/Unity/dataset/solo_22'\n",
    "# training_dir = './data/train'\n",
    "# testing_dir = './data/test'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 256,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[1124,  617],\n",
      "        [1136,  603],\n",
      "        [ 816,  603]], dtype=torch.int32)\n",
      "[1124  617]\n",
      "[1137  603]\n",
      "[815 604]\n",
      "------------------------------\n",
      "tensor([[759, 665]], dtype=torch.int32)\n",
      "[755 667]\n",
      "------------------------------\n"
     ]
    }
   ],
   "source": [
    "solo = Solo(data_path='D:/Unity/dataset/solo_22')\n",
    "\n",
    "\n",
    "def pos_to_pixel(capture, pos) -> np.ndarray:\n",
    "    r = R.from_quat(capture.rotation)\n",
    "    translation = np.array(capture.position)\n",
    "\n",
    "    camera_coordinates = r.inv().apply((pos - translation).T).T #- translation\n",
    "    pixel_coordinates = intrinsic @ camera_coordinates\n",
    "    pixels = pixel_coordinates / pixel_coordinates[-1]\n",
    "    return pixels[:2, 0].astype(np.int_)\n",
    "\n",
    "\n",
    "for frame_idx, frame in enumerate(solo.frames()):\n",
    "    # print(f'\\r{frame_idx}/{len(solo.frames())}', end='')\n",
    "    for i, capture in enumerate(frame.captures):\n",
    "        resolution = np.array(capture.dimension)\n",
    "\n",
    "        intrinsic = np.array([capture.matrix]).reshape((3, 3))\n",
    "        intrinsic /= intrinsic[-1,-1]\n",
    "        # intrinsic *= np.array([-resolution[0]/2, resolution[1]/2, 1])\n",
    "        # print(intrinsic)\n",
    "        # intrinsic[0, -1] = resolution[0]/2\n",
    "        # intrinsic[1, -1] = resolution[1]/2\n",
    "\n",
    "        translation = np.array(capture.position)\n",
    "        # print(translation)\n",
    "\n",
    "        gt_pixels = {}\n",
    "        bboxes = [anno for anno in capture.annotations if isinstance(anno, BoundingBox2DAnnotation)][0]\n",
    "        for bbox in bboxes.values:\n",
    "            pixel = np.array(bbox.origin) + np.array(bbox.dimension)/2\n",
    "            gt_pixels[bbox.instanceId] = pixel.astype(np.int_)\n",
    "\n",
    "        r = R.from_quat(capture.rotation)\n",
    "        pixels = {}\n",
    "        anno_3d = [anno for anno in capture.annotations if isinstance(anno, BoundingBox3DAnnotation)][0]\n",
    "        poses = []\n",
    "        for u, anno in enumerate(anno_3d.values):\n",
    "            t = np.array(anno.translation)\n",
    "            pos = np.array(r.apply(t.T).T + translation)\n",
    "            poses.append(pos)\n",
    "\n",
    "            # if u == 1: break\n",
    "            # print(pos)\n",
    "\n",
    "        #     # camera_coordinates = r.inv().apply((pos - translation).T).T\n",
    "        #     ueler = r.as_matrix()\n",
    "        #     # print('pos', pos, pos - translation)\n",
    "        #     camera_coordinates = (pos - translation) @ ueler\n",
    "        #     # print(camera_coordinates)\n",
    "        #     _intrinsic = intrinsic * np.array([-resolution[0]/2, resolution[1]/2, 1])\n",
    "        #     # print(camera_coordinates.shape)\n",
    "        #     pixel_coordinates = camera_coordinates @ _intrinsic\n",
    "        #     # print(pixel_coordinates)\n",
    "        #     # print(camera_coordinates.shape, intrinsic.shape)\n",
    "        #     pixel = pixel_coordinates / pixel_coordinates[-1]\n",
    "        #     pixel[:2] += resolution/2\n",
    "        #     pixels[anno.instanceId] = pixel[:2].astype(np.int_)\n",
    "        # poses = np.array(poses)\n",
    "        # # print(poses.shape)\n",
    "        # camera_coordinates = (poses - translation[np.newaxis, ...]) @ ueler\n",
    "        # # print(camera_coordinates.shape)\n",
    "        # pixel_coordinates = camera_coordinates @ _intrinsic\n",
    "        # pixel = pixel_coordinates / pixel_coordinates[:, -1]\n",
    "        # pixel[:, :2] += resolution/2\n",
    "        # print(pixel[:, :2].astype(np.int_))\n",
    "        \n",
    "        camera = utils.Camera.from_unity(capture)\n",
    "        print(\n",
    "            camera(torch.tensor(poses), [1920, 1080, 1])\n",
    "        )\n",
    "        \n",
    "        for key in gt_pixels.keys():\n",
    "            print(gt_pixels[key]) #, pixels[key])\n",
    "        # break\n",
    "        print('-'*30)\n",
    "    break\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 214,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([256., 256.])"
      ]
     },
     "execution_count": 214,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "resolution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.linalg.inv(intrinsic).dot((pixel - resolution)[:, 0])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "mpca",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
